{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 7: Estimating Causal Effects via Instrumental Variables\n",
    "Welcome to the seventh DS102 lab! \n",
    "\n",
    "The goals of this lab is to implement and get better understanding of instrumental variables discussed in [Discussion 06](https://piazza.com/class/k5ofad3nps24c1?cid=199). We highly recommend that you watch the video for [Discussion 06](https://piazza.com/class/k5ofad3nps24c1?cid=199) before attempting this lab.\n",
    "\n",
    "The code you need to write is commented out with a message \"TODO: fill in\".\n",
    "\n",
    "\n",
    "## Course Policies\n",
    "\n",
    "**Collaboration Policy**\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about the labs, we ask that you **write your solutions individually**. If you do discuss the assignments with others please **include their names** by adding a cell below.\n",
    "\n",
    "**Submission**: to submit this assignment, rerun the notebook from scratch (by selecting Kernel > Restart & Run all), and then print as a pdf (File > download as > pdf) and submit it to Gradescope.\n",
    "\n",
    "\n",
    "**This assignment should be completed and submitted before Thursday March 19, 2020 at 11:59 PM.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write collaborator names here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Instrumental Variables Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that we measure $X_1$, the number of books a student read in the last year, and we are intrested in determing how $X_1$ affects an observed target outcome $Y$, the student's SAT score. The effect we are interested in is **causal** because we want to know how $Y$ changes if all randomness other than $X_1$ remains fixed, and only $X_1$ changes. We will refer to $X_1$ as the \"treatment\". In general, $X_1$ might be multi-dimensional, however for the purpose of this exercise we take $X_1 \\in\\mathbb{R}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose there's also a confounder $X_2$, which is the income of the student's family. We don't observe $X_2$, but it affects both the number of books the student reads (wealthier families may have more access to books) and the student's SAT score (wealthier students may have more access to SAT tutoring).\n",
    "\n",
    "We assume that the outcome is generated as a linear function of the confounder $X_2$ and treatment $X_1$, with additive noise $\\epsilon$:\n",
    "$$$$\n",
    "$$Y = \\beta_1 X_1 + \\beta_2 X_2 + \\epsilon.$$\n",
    "\n",
    "The goal is to estimate $\\beta_1$, the true causal effect of the number of books a student reads on their SAT score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Danger of bias\n",
    "As we saw in Discussion 06, if the confounder $X_2$ is highly correlated with $X_1$, performing ordinary least squares (OLS) on the observed data $X_1$, $Y$ can lead to very biased results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instrumental variables (IVs) and two-stage least squares (2SLS)\n",
    "\n",
    "One way to get around this issue is by using **instrumental variables (IVs)**. A valid instrument $Z$ is a variable which is independent of the confounder $X_2$, and affects $Y$ only through $X_1$. For example, as discussed in Discussion 06, we can create such an instrument $Z$ by employing *encouragement design*, where we randomly select students and encourage them to read by organizing a “readathon” at their school. Let $Z$ be the number of days that the organized readathon lasts for the given student. \n",
    "\n",
    "Using the instrumental variable $Z$, we can estimate $\\beta_1$ by first \"guessing\" $X_1$ from $Z$ using ordinary least squares (OLS) (denoted $\\hat X_1$), and then regressing $Y$ onto $\\hat X_1$ (instead of $X_1$) using OLS as well. This procedure is known as **two-stage least squares (2SLS)**. \n",
    "\n",
    "In this lab, we will observe the bias that can occur when naively performing OLS on the observed data $X_1, Y$, and also how employing 2SLS can achieve a better estimate of $\\beta_1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Model setup\n",
    "\n",
    "Suppose that we have historical data from $n=10,000$ different students. Suppose we observe the following variables: \n",
    "\n",
    "$X_1^{(i)} =$ number of books the student read in the last year, \n",
    "\n",
    "$Z^{(i)} = $ whether or not there was a \"readathon\" at the student's school, \n",
    "\n",
    "$Y^{(i)} = $ the student's SAT score. \n",
    "\n",
    "Suppose that the student's family income $X_2^{(i)}$ affects both $X_1^{(i)}$ and $Y^{(i)}$, but is not observed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10000 # sample size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the data\n",
    "\n",
    "Each student participates in a readathon that lasts for $20$ days on average, with a standard deviation of $5$ days:\n",
    "$$Z^{(i)} \\sim \\text{Normal}(20,5)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy array of length n, where each entry is Z^{(i)}.\n",
    "Z = np.random.normal(20,5,n)\n",
    "\n",
    "plt.xlabel(\"TODO: fill this in\")\n",
    "plt.ylabel(\"Number of students\")\n",
    "plt.hist(Z)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Student $i$'s family income is normally distributed, where $X_2^{(i)}$ is the family's annual income (in thousands):\n",
    "$$X_2^{(i)} \\sim \\text{Normal}(50, 10)$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy array of length n, where the ith entry is student i's annual income\n",
    "X_2 = np.random.normal(50,10,n) \n",
    "\n",
    "plt.xlabel(\"TODO: fill this in\")\n",
    "plt.ylabel(\"Number of students\")\n",
    "plt.hist(X_2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of books a student reads is linear in whether or not there was a readathon and the student's family income:\n",
    "$$X_1 = \\gamma_1 Z + \\gamma_2 X_2 + \\epsilon',$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_1 = 1 # number of additional books read per day when there's a readathon\n",
    "gamma_2 = 1 # number of books read vs. family income\n",
    "eps_prime = np.random.normal(0,5,n) # noise for number of books read\n",
    "X_1 = gamma_1 * Z + gamma_2 * X_2 + eps_prime\n",
    "\n",
    "plt.xlabel(\"TODO: fill this in\")\n",
    "plt.ylabel(\"Number of students\")\n",
    "plt.hist(X_1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The student's SAT score is linear in the number of books the student read and the student's family income:\n",
    "$$Y = \\beta_1 X_1 + \\beta_2 X_2 + \\epsilon.$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_1 = 5 # true relationship between books read and SAT score\n",
    "beta_2 = 12 # relationship between SAT score and family income\n",
    "eps = np.random.normal(0,10,n) # noise for SAT score\n",
    "Y = beta_1 * X_1 + beta_2 * X_2 + eps\n",
    "\n",
    "plt.xlabel(\"TODO: fill this in\")\n",
    "plt.ylabel(\"Number of students\")\n",
    "plt.hist(Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal: estimate $\\beta_1$, the true causal effect of the number of books a student reads on their SAT score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Naive OLS: OLS on the observed variables $X_1$, $Y$.\n",
    "The confounding variable $X_2$ (family income) is unfortunately unobserved. We will start by somewhat \"naively\" attempting to estimate the causal effect $\\beta_1$ by using plain linear regression (OLS) on the observed variables $X_1$ and $Y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No TODOs here, just run this cell and understand what this function is doing.\n",
    "def beta_hat_with_intercept(input_array, target_array):\n",
    "    \"\"\"Calculates the OLS estimator parameters. The returned parameters include an intercept term.\n",
    "    \n",
    "    Args:\n",
    "      input_array: numpy array with n entries, where each entry corresponds with a feature value for a given student.\n",
    "      target_array: numpy array with n entries, where each entry corresponds with a label value for a given student.\n",
    "    \n",
    "    Returns:\n",
    "      numpy array with 2 entries, where the entries are [intercept, beta_hat]. The intercept is a constant term, \n",
    "      so the final OLS predictions should be predictions = intercept + beta_hat * input_array.\n",
    "    \"\"\"\n",
    "    ols_features_w_const = sm.add_constant(input_array) # prepend a constant feature for intercept term\n",
    "    ols_model = sm.OLS(target_array, ols_features_w_const)\n",
    "    ols_results = (ols_model.fit()).params # predicted coefficients\n",
    "    return ols_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fit OLS parameters to predict Y from X_1.\n",
    "beta_hat_naive_with_intercept = beta_hat_with_intercept(input_array=\"\"\"TODO: fill in\"\"\", target_array=\"\"\"TODO: fill in\"\"\")\n",
    "\n",
    "beta_hat_naive = beta_hat_naive_with_intercept[1]\n",
    "print(\"Naive OLS estimate of beta_1:\", beta_hat_naive)\n",
    "print(\"True beta_1:\", beta_1)\n",
    "print(\"Absolute error:\", np.abs(beta_hat_naive - beta_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Instrumental variables and 2SLS\n",
    "\n",
    "To eliminate the bias, we turn to instrumental variables. In the first stage, we \"predict\" the number of books a student read $X_1$ from whether or not they had a readathon, $Z$, producing an estimate $\\hat{X_1}$. Then, in the second stage, we regress the SAT score $Y$ onto the predicted number of books read $\\hat{X_1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No TODOs here, just run this call and understand what this function is doing.\n",
    "def compute_OLS_predictions(input_array, input_params):\n",
    "    \"\"\"Calculates OLS predictions from fitted OLS parameters, input_params.\n",
    "    \n",
    "    Args:\n",
    "      input_array: numpy array with n entries, where each entry corresponds with a feature value for a given student.\n",
    "      input_params: numpy array with 2 entries, where the entries are [intercept, beta_hat]. \n",
    "        The intercept is a constant term, so the final OLS predictions should be \n",
    "        predictions = intercept + beta_hat*input_array.\n",
    "\n",
    "    Returns:\n",
    "      numpy array with n entries containing predictions from input_array.\n",
    "    \"\"\"\n",
    "    predictions = input_params[0] + input_params[1] * input_array \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3a) Stage 1: Predict treatment variable $\\hat{X}_1$ from instrumental variable $Z$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 1 of 2SLS.\n",
    "# TODO: Fit OLS parameters to predict X_1 from Z\n",
    "X_1_hat_params = beta_hat_with_intercept(input_array=\"\"\"TODO: fill in\"\"\", target_array=\"\"\"TODO: fill in\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Compute predictions using the fitted parameters above.\n",
    "X_1_hat = compute_OLS_predictions(input_params=\"\"\"TODO: fill in\"\"\", input_array=\"\"\"TODO: fill in\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3b) Stage 2: Estimate target $Y$ from predicted treatment variable $\\hat{X}_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stage 2 of 2SLS.\n",
    "# TODO: Fit OLS parameters to predict Y from the predicted X_1_hat.\n",
    "beta_hat_2SLS_with_itercept = beta_hat_with_intercept(input_array=\"\"\"TODO: fill in\"\"\", target_array=\"\"\"TODO: fill in\"\"\")\n",
    "\n",
    "beta_hat_2SLS = beta_hat_2SLS_with_itercept[1]\n",
    "print(\"2SLS estimate of beta_1:\", beta_hat_2SLS)\n",
    "print(\"True beta_1:\", beta_1)\n",
    "print(\"Absolute error:\", np.abs(beta_hat_2SLS - beta_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3c) Question: Which technique produced a better estimate of $\\beta_1$, naive OLS (part 2) or 2SLS (part 3)?\n",
    "\n",
    "TODO: fill in your answer.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
