{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 12: Differential Privacy\n",
    "Welcome to the twelfth (and final) DS102 lab!!\n",
    "\n",
    "The goal of this lab is to gain a better understanding of differential privacy. We will observe what happens after the Laplace mechanism is applied to an estimator, discussed in [Discussion 11](https://www.data102.org/assets/disc/disc11/disc11_sol.pdf) and [Lecture 29](https://www.data102.org/assets/notes/notes29.pdf). This demonstration is related to an experiment done by [Duchi et al. 2017](https://arxiv.org/abs/1604.02390).\n",
    "\n",
    "\n",
    "## Course Policies\n",
    "\n",
    "**Collaboration Policy**\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about the labs, we ask that you **write your solutions individually**. If you do discuss the assignments with others please **include their names** in the cell below.\n",
    "\n",
    "**Submission**: to submit this assignment, rerun the notebook from scratch (by selecting Kernel > Restart & Run all), and then print as a pdf (File > download as > pdf) and submit it to Gradescope.\n",
    "\n",
    "\n",
    "**This assignment should be completed and submitted before Thursday April 30, 2020 at 11:59 PM.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import bernoulli\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load the Dataset: National Estimates of Drug-Related Emergency Department Visits (NEDREDV)\n",
    "\n",
    "In this lab, we will analyze drug use data from the [National Estimates\n",
    "of Drug-Related Emergency Department Visits (NEDREDV)](https://www.samhsa.gov/data/report/national-estimates-drug-related-emergency-department-visits-2004-2011-all-visits).\n",
    "\n",
    "The NEDREDV dataset tracks the number of hospital emergency department visits related to drug usage in a given year. We look at data from 2004 and consider the number of hospital admissions for $d = 27$ common drugs:  *Alcohol, Cocaine, Heroin, Marijuana, Stimulants, Amphetamines, Methamphetamine, MDMA, LSD, PCP, Antidepressants, Antipsychotics, Miscellaneous hallucinogens, Inhalants, lithium, Opiates,\n",
    "Opiates unspecified, Narcotic analgesics, Buprenorphine, Codeine, Fentanyl, Hydrocodone, Methadone, Morphine,\n",
    "Oxycodone, Ibuprofen, and Muscle relaxants.*\n",
    "\n",
    "The NEDREDV dataset that we import includes the $d = 27$ drugs, and the observed probability that a person admitted to the hospital for drug abuse in 2004 used drug $j$. Note that a person admitted to the hospital could have used multiple drugs simultaneously, so the probabilities do not sum to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nedredv_df = pd.read_csv('nedredv_probs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nedredv_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Simulating a privacy-sensitive dataset\n",
    "\n",
    "The NEDREDV dataset itself does not contain the actual drug usage of each individual person admitted to the hospital: it only contains rates of the total number of people admitted to the hospital for using each drug. For the purposes of this lab, we will instead *simulate* a  privacy-sensitive dataset that contains the drug usage of the individuals admitted to the hospital. We will generate a dataset $X = \\{X_1, . . . , X_N \\}$ where each $X_i \\in \\{0, 1\\}^d$ represents an individual admitted to the hospital, and $X_{i,j}$ is 1 if the individual abuses drug $j$ and 0 otherwise. Since drug use is a sensitive topic, it would certainly be a privacy problem if such a dataset $X$ containing the drug usage of individuals admitted to the hospital were made public (and it would likely violate [HIPAA](https://www.hhs.gov/hipaa/index.html)). \n",
    "\n",
    "To generate this privacy-sensitive dataset, let $p_j$ be the observed probability that a person admitted to the hospital used drug $j$ according to the NEDREDV data from 2004. We draw $$X_{i,j} \\sim Bernoulli(p_j)$$ independently for all $i = 1,...,N$ and for all $j = 1,...,d$. This results in a set of hypothetical individuals $X_1,...,X_N$ where the marginal counts $\\frac{1}{N}\\sum_{i=1}^N X_{i,j}$ yield approximately the correct drug use frequencies to match the NEDREDV data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: complete the function for simulating the privacy-sensitive data.\n",
    "def simulate_private_data(nedredv_df, N=30000):\n",
    "    \"\"\"Simulates the privacy-sensitive dataset with individual drug usage.\n",
    "    \n",
    "    Args: \n",
    "      nedredv_df, dataframe containing the drug and the probability that an admittee used the drug.\n",
    "      N, number of individuals to generate.\n",
    "      \n",
    "    Returns:\n",
    "      dataframe containing N rows where each row corresponds to an admitted individual, \n",
    "      and a 1 in a column corresponding to a given drug means that the individual used that drug.\n",
    "    \"\"\"\n",
    "    X = {}\n",
    "    for index, row in nedredv_df.iterrows(): \n",
    "        drug_name = row['Substance']\n",
    "        observed_probability = row['Probability']\n",
    "        X_row = bernoulli.rvs(\"\"\"TODO: fill this in\"\"\", size=N)\n",
    "        X[drug_name] = X_row\n",
    "    return pd.DataFrame(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_df = simulate_private_data(nedredv_df)\n",
    "X_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that each row of the dataframe X_df corresponds to an individual, $X_i$, and a $1$ in a column corresponding to a given drug means that the individual used that drug. An individual admitted to the hospital could have used multiple drugs simultaneously."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal: Mean estimation with differential privacy\n",
    "\n",
    "From now on, we will treat the dataset that we just generated as ground truth. We will seek to analyze statistics about this data without hurting the privacy of the individuals in the dataset that we just generated.\n",
    "\n",
    "Specifically, the statistic we want to estimate is the mean of the population:\n",
    "$\\theta = E[X]$. But, the catch is that we want to estimate this mean in a **differentially private** way. \n",
    "\n",
    "## The true mean\n",
    "Based on the way the data was generated, we know that the true mean of the distribution that the samples were drawn from is the original probabilities from the NEDREDV dataset. Our goal will be to estimate this true mean from the dataset that we generated in a differentially private way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_mean = nedredv_df['Probability'].to_numpy()\n",
    "print(true_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Differential privacy\n",
    "\n",
    "The idea behind differential privacy is that any given individual should be willing to participate in the statistical analysis\n",
    "because their participation in the study does not change the outcome of the study by very much;\n",
    "their personal information cannot be recovered from the results of either removing or adding them to the study. This applies to the individuals in the dataset we generated: removing any individual from the data should not change our mean estimate that much. Otherwise, it may be possible to recover the drug usage of an individual based on a mean estimate that includes the individual and another mean estimate that doesn't include the individual.\n",
    "\n",
    "Recall that for two datasets $X$ and $X'$ which differ in only one entry (e.g., differing in one individual), an $\\epsilon$-**differentially private algorithm** $\\mathcal{A}$ satisfies:\n",
    "\n",
    "$$\\mathbb{P}(\\mathcal{A}(X) = a) \\leq e^{\\epsilon}\\mathbb{P}(\\mathcal{A}(X')= a),$$\n",
    "\n",
    "for all possible output values $a$ of the algorithm $\\mathcal{A}$. In words, the probability of seeing any given output of a differentially private algorithm doesn't change much by replacing any one entry in the dataset.\n",
    "\n",
    "We will explore three algorithms for estimating the mean in this lab:\n",
    "\n",
    "1. **Algorithm 1: Non-private:** we will simply take the sample mean of the given data $X$, $$\\hat{\\theta} = \\mathcal{A}(X) = f(X) = \\frac{1}{N}\\sum_{i=1}^N X_i.$$ This is not differentially private: we can recover the drug usage of an individual if we estimate the mean before and after removing the individual.\n",
    "\n",
    "2. **Algorithm 2: Laplace mechanism:** To introduce differential privacy, we can apply the Laplace mechanism that we went over in [Discussion 11](https://www.data102.org/assets/disc/disc11/disc11_sol.pdf) and [Lecture 29](https://www.data102.org/assets/notes/notes29.pdf). Given the non-private estimator $f(X)$, we can add noise $\\xi_{\\epsilon}$: $$\\hat{\\theta} = \\mathcal{A}(X) = f(X) + \\xi_{\\epsilon} = \\left(\\frac{1}{N}\\sum_{i=1}^N X_i\\right) + \\xi_{\\epsilon}.$$ We will go over this algorithm in more detail later in the lab.\n",
    "\n",
    "3. **Algorithm 3: Locally differentially private Laplace mechanism:** another way to introduce differential privacy is to make the data locally differentially private. In the above Algorithm 2, we added a single noise parameter $\\xi_{\\epsilon}$ to the non-private estimate $f(X)$. As we discussed in [Lecture 29](https://www.data102.org/assets/notes/notes29.pdf), rather than adding noise to the aggregated $f(X)$, we could also add noise to each sensitive bit individually, $X_i$. $$\\hat{\\theta} = \\mathcal{A}(X) = f(X + \\xi_{\\epsilon}) = \\frac{1}{N}\\sum_{i=1}^N (X_i + \\xi_{\\epsilon}^i ).$$ We will also go over this algorithm in more detail later in the lab.\n",
    "\n",
    "Both Algorithm 2 and Algorithm 3 result in estimators $\\hat{\\theta}$ that are $\\epsilon$-differentially private. The difference between Algorithm 2 and Algorithm 3 is that Algorithm 3 introduces more noise overall by introducing noise $\\xi_{\\epsilon}^i$ into each row. However, the local approach of Algorithm 3 ensures privacy even if we don't trust the person or program calculating $f(X)$ in Algorithm 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.  Algorithm 1: Non-private\n",
    "\n",
    "We will now implement the three algorithms, and compare how well they accomplish the task of mean estimation. We'll start with Algorithm 1.\n",
    "\n",
    "For Algorithm 1, the obvious algorithm for mean estimation is to simply take the mean of the samples, $X_i$: \n",
    "\n",
    "$$\\hat{\\theta} = \\mathcal{A}(X) = f(X) = \\frac{1}{N}\\sum_{i=1}^N X_i$$\n",
    "\n",
    "However, this is clearly not differentially private: we can recover the drug usage of an individual if we estimate the mean before and after removing the individual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Implement Algorithm 1\n",
    "First, we need to implement the calculation of $\\hat{\\theta}$ using Algorithm 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: estimate the mean of the data using the non-private Algorithm 1.\n",
    "def alg_1_estimate(input_X_df):\n",
    "    \"\"\"Estimates the mean of the data using the non-private Algorithm 1.\n",
    "    \n",
    "    Args: \n",
    "      input_X_df: dataframe where each row corresponds to an individual, \n",
    "        and a 1 in a column corresponding to a given drug means that\n",
    "        the individual used that drug. \n",
    "        \n",
    "    Returns:\n",
    "      mean_estimate: d-dimensional numpy array containing mean of all of the rows in X_df.\n",
    "    \n",
    "    \"\"\"\n",
    "    mean_estimate = # TODO: fill in the Algorithm 1 mean estimate.\n",
    "    return mean_estimate\n",
    "\n",
    "print(\"Mean estimate from algorithm 1:\", alg_1_estimate(X_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Compute the max error of the mean estimate\n",
    "To judge how good our mean estimate was, we will use the max error, or the [infinity-norm](https://en.wikipedia.org/wiki/Norm_(mathematics)#Maximum_norm_(special_case_of:_infinity_norm,_uniform_norm,_or_supremum_norm)): \n",
    "$$||\\hat{\\theta} - \\theta||_\\infty = \\max_i{|\\hat{\\theta}_i - \\theta_i}|$$\n",
    "\n",
    "This just finds the max difference between any two coordinates of the true mean $\\theta$ and the estimated mean $\\hat{\\theta}$.\n",
    "\n",
    "Now, we will implement the max error function, and calculate the max error of Algorithm 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: compute the max error between the estimated mean and the true mean.\n",
    "def max_error(estimated_mean, true_mean):\n",
    "    \"\"\"Computes the maximum error between the estimated mean and the true mean.\n",
    "    \n",
    "    Args:\n",
    "      estimated_mean: numpy array of length d containing the estimated mean.\n",
    "      true_mean: numpy array of length d containing the true mean.\n",
    "    \n",
    "    Returns:\n",
    "      max_error: the max error between the estimated_mean and true_mean. \n",
    "        This should be the max of the absolute value of all of the coordinates\n",
    "        of estimated_mean - true_mean.\n",
    "    \"\"\"\n",
    "    max_error = # TODO: calculate the max error.\n",
    "    return max_error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Max error of Algorithm 1:\", max_error(alg_1_estimate(X_df), true_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Algorithm 2: Laplace mechanism\n",
    "To introduce differential privacy, we can apply the Laplace mechanism that we went over in [Discussion 11](https://www.data102.org/assets/disc/disc11/disc11_sol.pdf) and [Lecture 29](https://www.data102.org/assets/notes/notes29.pdf). Given the non-private estimator $f(X)$, we can add noise $\\xi_{\\epsilon}$:\n",
    "$$\\hat{\\theta} = \\mathcal{A}(X) = f(X) + \\xi_{\\epsilon} = \\left(\\frac{1}{N}\\sum_{i=1}^N X_i\\right) + \\xi_{\\epsilon}$$\n",
    "\n",
    "\n",
    "$\\xi_{\\epsilon} \\in \\mathbb{R}^d$ has independent coordinates, each distributed according to the zero-mean Laplace distribution with parameter $\\frac{\\Delta_f}{\\epsilon}$, denoted $\\text{Lap}(0,\\frac{\\Delta_f}{\\epsilon})$. \n",
    "\n",
    "$\\Delta_f$ is the sensitivity of the function $f$, defined as \n",
    "$$\\Delta_f = \\max_{\\text{neighboring } X,X'} ||f(X) - f(X')||_1,$$\n",
    "where $||.||_1$ is the [1-norm](https://en.wikipedia.org/wiki/Norm_(mathematics)#Taxicab_norm_or_Manhattan_norm). We need to use the 1-norm here because $f(X) \\in \\mathbb{R}^d$.\n",
    "\n",
    "Solving for this,\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\Delta_f &= \\max_{\\text{neighboring } X,X'} ||f(X) - f(X')||_1 \\\\\n",
    "&= \\max_{\\text{neighboring } X,X'} \\bigg|\\bigg|\\frac{1}{N}\\sum_{i=1}^N X_i - \\frac{1}{N}\\sum_{i=1}^N X_i'\\bigg|\\bigg|_1 \\\\\n",
    "&= \\frac{d}{N}\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "In [Discussion 11](https://www.data102.org/assets/disc/disc11/disc11_sol.pdf), we showed that the above algorithm $\\mathcal{A}(X)$ is $\\epsilon$-differentially private. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Implement Algorithm 2\n",
    "\n",
    "Calculate $\\hat{\\theta}$ using Algorithm 2 above. \n",
    "\n",
    "Plugging in the calculation for $\\Delta_f$ above, we have $\\xi_{\\epsilon} \\in \\mathbb{R}^d$ has independent coordinates, each distributed according to the zero-mean Laplace distribution with scale parameter $\\frac{d}{N\\epsilon}$, denoted $\\text{Lap}(0,\\frac{d}{N\\epsilon})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: estimate the mean of the data using Algorithm 2.\n",
    "def alg_2_estimate(input_X_df, epsilon=0.5):\n",
    "    \"\"\"Estimates the mean of the data using Algorithm 2.\n",
    "    \n",
    "    Args: \n",
    "      input_X_df: dataframe where each row corresponds to an individual, \n",
    "        and a 1 in a column corresponding to a given drug means that\n",
    "        the individual used that drug. \n",
    "      epsilon: differential privacy parameter.\n",
    "        \n",
    "    Returns:\n",
    "      mean_estimate: d-dimensional numpy array containing the mean estimate.\n",
    "    \n",
    "    \"\"\"\n",
    "    d = len(input_X_df.columns)\n",
    "    N = len(input_X_df)\n",
    "    laplace_scale = # TODO: fill in the scale parameter for the Laplace distribution.\n",
    "    xi = np.random.laplace(0, laplace_scale, size=d)\n",
    "    mean_estimate = # TODO: fill in the mean estimate for Algorithm 2.\n",
    "    return mean_estimate\n",
    "\n",
    "print(\"Mean estimate from Algorithm 2:\", alg_2_estimate(X_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Max error of Algorithm 2:\", max_error(alg_2_estimate(X_df), true_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Algorithm 3: Locally differentially private Laplace mechanism\n",
    "Finally, another way to introduce differential privacy is to make the data locally differentially private. In the above Algorithm 2, we added a single noise parameter $\\xi_{\\epsilon}$ to the non-private estimate $f(X)$. As we discussed in [Lecture 29](https://www.data102.org/assets/notes/notes29.pdf), rather\n",
    "than adding noise to the aggregated $f(X)$, we could also add noise to each sensitive bit individually, $X_i$. \n",
    "\n",
    "$$\\hat{\\theta} = \\mathcal{A}(X) = f(X + \\xi_{\\epsilon}) = \\frac{1}{N}\\sum_{i=1}^N (X_i + \\xi_{\\epsilon}^i )$$\n",
    "\n",
    "Here, $\\xi_{\\epsilon} \\in \\mathbb{R}^{N \\times d}$ is making each row in the data differentially private before it even reaches the function $f(X)$. For each individual row $X_i$, $\\xi_{\\epsilon}^i \\in \\mathbb{R}^d$ has independent coordinates, each distributed according to the zero-mean Laplace distribution with parameter $\\frac{\\Delta_{X_i}}{\\epsilon}$, denoted $\\text{Lap}(0,\\frac{\\Delta_{X_i}}{\\epsilon})$. \n",
    "\n",
    "$\\Delta_{X_i}$ is the sensitivity of changing a single row $X_i$:\n",
    "$$\\Delta_{X_i} = \\max_{X_i \\neq X_i'} || X_i - X_i')||_1 = d$$\n",
    "\n",
    "It can be similarly shown that adding noise $\\xi_{\\epsilon}^i$ to each row $X_i$ makes each row itself differentially private, and by the Composition Guarantees for Differential Privacy discussed in [Lecture 29](https://www.data102.org/assets/notes/notes29.pdf), this locally differentially private algorithm $\\mathcal{A}(X)$ is also $\\epsilon$-differentially private. \n",
    "\n",
    "The difference between Algorithm 2 and Algorithm 3 is that Algorithm 3 introduces more noise overall by introducing noise $\\xi_{\\epsilon}^i$ into each row. However, the local approach of Algorithm 3 ensures privacy even if we don't trust the person or program calculating $f(X)$ in Algorithm 2.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Implement Algorithm 3\n",
    "\n",
    "Calculate $\\hat{\\theta}$ using Algorithm 3 above. \n",
    "\n",
    "Plugging in the calculation for $\\Delta_{X_i}$ above, we have $\\xi_{\\epsilon}^i \\in \\mathbb{R}^d$ has independent coordinates, each distributed according to the zero-mean Laplace distribution with parameter $\\frac{d}{\\epsilon}$, denoted $\\text{Lap}(0,\\frac{d}{\\epsilon})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: estimate the mean of the data using Algorithm 3.\n",
    "def alg_3_estimate(input_X_df, epsilon=0.5):\n",
    "    \"\"\"Estimates the mean of the data using Algorithm 3.\n",
    "    \n",
    "    Args: \n",
    "      input_X_df: dataframe where each row corresponds to an individual, \n",
    "        and a 1 in a column corresponding to a given drug means that\n",
    "        the individual used that drug. \n",
    "      epsilon: differential privacy parameter.\n",
    "        \n",
    "    Returns:\n",
    "      mean_estimate: d-dimensional numpy array containing the mean estimate.\n",
    "    \n",
    "    \"\"\"\n",
    "    d = len(input_X_df.columns)\n",
    "    N = len(input_X_df)\n",
    "    laplace_scale = # TODO: fill in the scale parameter for the Laplace distribution.\n",
    "    \n",
    "    # Adds the xi_i noise to each row X_i. \n",
    "    X = input_X_df.to_numpy(dtype=float)\n",
    "    for i in range(len(X)):\n",
    "        xi_i = np.random.laplace(0, laplace_scale, size=d)\n",
    "        X[i] += xi_i\n",
    "        \n",
    "    mean_estimate = # TODO: fill in the mean estimate for Algorithm 3.\n",
    "    return mean_estimate\n",
    "\n",
    "print(\"Mean estimate from Algorithm 3:\", alg_3_estimate(X_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Max error of Algorithm 3:\", max_error(alg_3_estimate(X_df), true_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Question: rank all three algorithms in order of how close the mean estimate was to the true mean. For the algorithm that had the worst estimate, why do you think it had the worst estimate?  \n",
    "\n",
    "TODO: fill in your answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Question: Both Algorithm 2 and Algorithm 3 are $\\epsilon$-differentially private, but have different performances for mean estimation. Can you come up with a hypothetical practical scenario where you might want to use Algorithm 3 instead of Algorithm 2?\n",
    "\n",
    "TODO: fill in your answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
