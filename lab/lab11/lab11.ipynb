{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 11: Bootstrap and Hypothesis Testing\n",
    "Welcome to the eleventh DS102 lab! \n",
    "\n",
    "The goal of this lab is to implement bootstrap techniques to perform hypothesis testing in settings where it would have otherwise been very difficult with our previous techniques. We will be implementing the same example that we discussed in [Discussion 10](https://www.data102.org/assets/disc/disc10/disc10_sol.pdf). The discussion and lab are adapted from an example from [Statistics 24600 at UChicago](http://galton.uchicago.edu/~eichler/stat24600/Handouts/bootstrap.pdf).\n",
    "\n",
    "\n",
    "## Course Policies\n",
    "\n",
    "**Collaboration Policy**\n",
    "\n",
    "Data science is a collaborative activity. While you may talk with others about the labs, we ask that you **write your solutions individually**. If you do discuss the assignments with others please **include their names** in the cell below.\n",
    "\n",
    "**Submission**: to submit this assignment, rerun the notebook from scratch (by selecting Kernel > Restart & Run all), and then print as a pdf (File > download as > pdf) and submit it to Gradescope.\n",
    "\n",
    "\n",
    "**This assignment should be completed and submitted before Thursday April 23, 2020 at 11:59 PM.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from math import pi, exp, sqrt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Goal: testing for multimodality\n",
    "Suppose that $X_1, . . . , X_n$ are an i.i.d. sample from a distribution with continuous density $p(x)$.\n",
    "One important property of the density $p(x)$ is the number of modes it has. Multimodality of\n",
    "the density indicates a heterogeneity in the data. In this lab, we will demonstrate how to perform a hypothesis test to determine whether a distribution is multimodal. We'll use the bootstrap to perform this hypothesis test.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Galaxy data\n",
    "\n",
    "In this lab we will be working with galaxy data. The dataset contains velocities in km/sec of 82 galaxies from 6 well-separated conic sections of an unfilled survey\n",
    "of the Corona Borealis region. The distribution\n",
    "of galaxy velocities provides information about the structure of the far universe—in\n",
    "particular, a multimodal distribution of velocities is seen as evidence for the existence\n",
    "of voids and superclusters.\n",
    "\n",
    "Let $X_1, . . . , X_{n}$ be the velocities of each galaxy, where $X_i$ is the velocity of the $i$th galaxy and we observe $n=82$ galaxies.\n",
    "\n",
    "We want to test whether or not the distribution that the $X_i$'s are drawn from is multimodal. Let the null and alternative hypotheses be defined as follows:\n",
    "\n",
    "$$H_0: m(p) = 1$$ \n",
    "$$H_A: m(p) > 1$$ \n",
    "\n",
    "where $p$ is the distribution of galaxy velocities, and $m$ is the number of modes of a distribution.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data\n",
    "\n",
    "First, we'll load the data and see what the histogram looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "galaxies_df = pd.read_csv('galaxies.csv', index_col=0, header=0, names=['velocity'])\n",
    "# Divide all entries by 1000 for ease of reading.\n",
    "galaxies_df['velocity'] = galaxies_df['velocity'] / 1000\n",
    "X_observed = galaxies_df['velocity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(X_observed)\n",
    "plt.title(\"Histogram of galaxy velocities\")\n",
    "plt.xlabel(\"Velocity of galaxy, X (thousands of km/s)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Estimating the density and test statistic\n",
    "\n",
    "In order to infer whether or not the $X_1,...,X_{n}$ were drawn from a multimodal distribution, we need to come up with a test statistic that somehow reflects how suitable a unimodal distribution is for\n",
    "modeling this data. \n",
    "\n",
    "To do this, we first need to come up with a model for the density function itself. We’ll model our\n",
    "data using *kernel density estimation*: \n",
    "\n",
    "$$\\hat{p}_h(x) = \\frac{1}{nh} \\sum_{i=1}^n K\\left(\\frac{x - X_i}{h}\\right)$$\n",
    "\n",
    "$\\hat{p}_h(x)$ will be our estimate of the density function. \n",
    "\n",
    "As explained in Discussion 10, $K$ is some non-negative kernel function that captures the influence of each data\n",
    "point $X_i$ on the density of an arbitrary point $x$. A common choice of kernel is the\n",
    "Gaussian kernel, which is what we will use from now on in this lab: \n",
    "\n",
    "$$K(x) = \\frac{1}{\\sqrt{2\\pi}} \\exp(-x^2/2)$$\n",
    "\n",
    "In addition, the parameter $h > 0$ is a bandwidth parameter that captures how close data points $X_i$ must be to $x$ to influence its density: for larger values of $h$, more data points have an\n",
    "influence on the density at $x$, whereas for smaller values of $h$, only data points very close\n",
    "to $x$ influence it.\n",
    "\n",
    "Both $K$ and $h$ are user-selected. In this lab, we will use the above Gaussian kernel for $K(x)$. \n",
    "\n",
    "It can be shown that the number of modes of $\\hat{p}_h(x)$ (a.k.a. $m(\\hat{p}_h(x))$) decreases monotonically as $h$ increases. Therefore, $h$ will be an important tool in our hypothesis test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Plot the density estimates $\\hat{p}_h(x)$\n",
    "\n",
    "Using the kernel function $K(x) = \\frac{1}{\\sqrt{2\\pi}} \\exp(-x^2/2)$, we will first plot $\\hat{p}_h(x)$ to get a sense of what these density estimates look like for different values of $h$.\n",
    "\n",
    "\\begin{align*}\n",
    "\\hat{p}_h(x) &= \\frac{1}{nh} \\sum_{i=1}^n K\\left(\\frac{x - X_i}{h}\\right) \\\\\n",
    "&= \\frac{1}{nh} \\sum_{i=1}^n \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{(x - X_i)^2}{2h^2}\\right) \\\\\n",
    "&= \\frac{1}{nh \\sqrt{2\\pi}} \\sum_{i=1}^n \\exp\\left(-\\frac{(x - X_i)^2}{2h^2}\\right) \\\\\n",
    "\\end{align*}\n",
    "\n",
    "Using the final simplified form above, implement a function that calculates $\\hat{p}_h(x)$ at a given point $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement the density function \\hat{p}_h(x) above.\n",
    "def phat(x, h, X):\n",
    "    \"\"\"Calculates phat_h(x) at a single point x.\n",
    "    \n",
    "    Args: \n",
    "      x: float, point at which to evaluate the derivative.\n",
    "      h: float, bandwidth parameter in phat_h.\n",
    "      X: array of floats of length n containing the observed galaxy velocities.\n",
    "      \n",
    "    Returns:\n",
    "      float, the value of phat_h(x) at the given point x.\n",
    "    \"\"\"\n",
    "    density = # TODO: calculate the density function \\hat{p}_h(x).\n",
    "    return density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To test the function above, we now plot \\hat{p}_h(x) for different values of h.\n",
    "# TODO: plug in different values of h below, and observe how the estimated density changes.\n",
    "\n",
    "h = # TODO: try different values between 1 and 4.\n",
    "\n",
    "# Grid of xs at which to evaluate the derivative\n",
    "xs = np.arange(5,35,0.05)\n",
    "derivs = []\n",
    "for x in xs:\n",
    "    derivs.append(phat(x, h, X_observed))\n",
    "\n",
    "plt.plot(xs, derivs)\n",
    "plt.title(\"Density $\\hat{p}_h(x)$\")\n",
    "plt.ylabel(\"Density $\\hat{p}_h(x)$\")\n",
    "plt.xlabel(\"Velocity, x\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Question: For what values of $h$ does the density estimate $\\hat{p}_h(x)$ seem to fit the histogram of the data better (higher or lower values of $h$)? Does the density estimate $\\hat{p}_h(x)$ seem to contain more modes for higher values of $h$ or lower values of $h$?\n",
    "\n",
    "TODO: fill in your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Count the modes of $\\hat{p}_h(x)$\n",
    "\n",
    "Now we will write a function that counts the number of modes of a given density estimate $\\hat{p}_h(x)$. This is the $m(p)$ function mentioned above. \n",
    "\n",
    "To do this, we say that a density function $p$ has a mode everywhere the function $p(x)$ has an increase followed by a decrease. That is, $p(x)$ has an additional mode for each time the derivative of the function $p(x)$ transitions from positive (or 0) to negative.\n",
    "\n",
    "Following the above definition, to count the number of modes in $\\hat{p}_h(x)$, first we will take the derivative, $$\\frac{d}{dx}\\hat{p}_h(x).$$\n",
    "\n",
    "Then, we will count the number of times that the derivative transitions from positive (or 0) to negative over a grid of $x$'s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Calculate the derivative $\\frac{d}{dx}\\hat{p}_h(x).$\n",
    "\n",
    "Using the kernel function $K(x) = \\frac{1}{\\sqrt{2\\pi}} \\exp(-x^2/2)$, we will now calculate the derivative $\\frac{d}{dx}\\hat{p}_h(x)$ by applying the chain rule.\n",
    "\n",
    "\\begin{align*}\n",
    "\\frac{d}{dx}\\hat{p}_h(x) &= \\frac{d}{dx} \\frac{1}{nh} \\sum_{i=1}^n K\\left(\\frac{x - X_i}{h}\\right) \\\\\n",
    "&= \\frac{1}{nh} \\sum_{i=1}^n \\frac{d}{dx} K\\left(\\frac{x - X_i}{h}\\right) \\\\\n",
    "&= \\frac{1}{nh} \\sum_{i=1}^n \\frac{1}{h} K'\\left(\\frac{x - X_i}{h}\\right) \\\\\n",
    "&= \\frac{1}{nh^2} \\sum_{i=1}^n \\frac{1}{\\sqrt{2\\pi}} \\frac{-(x - X_i)}{h} \\exp\n",
    "\\left(-\\frac{\\left(\\frac{x - X_i}{h}\\right)^2}{2}\\right) \\\\\n",
    "&= \\frac{1}{nh^3 \\sqrt{2\\pi}} \\sum_{i=1}^n (X_i - x)\\exp\n",
    "\\left(-\\frac{(x - X_i)^2}{2h^2}\\right) \\\\\n",
    "\\end{align*}\n",
    "\n",
    "Using the final simplified form of the derivative above, implement a function that calculates $\\frac{d}{dx}\\hat{p}_h(x)$ at a given point $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Implement the derivative of the density function \\hat{p}_h(x) above.\n",
    "def phat_derivative(x, h, X):\n",
    "    \"\"\"Calculates the derivative d/dx phat_h(x) at a single point x.\n",
    "    \n",
    "    Args: \n",
    "      x: float, point at which to evaluate the derivative.\n",
    "      h: float, bandwidth parameter in phat_h.\n",
    "      X: array of floats of length n containing the observed galaxy velocities.\n",
    "      \n",
    "    Returns:\n",
    "      float, the derivative d/dx phat_h(x) at the given point x.\n",
    "    \"\"\"\n",
    "    derivative = # TODO: calculate the derivative of the density function \\hat{p}_h(x).\n",
    "    return derivative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To test the function above, we now plot the derivative of phat_h(x) for different values of h.\n",
    "# TODO: plug in different values of h below, and observe how the derivative of the density changes.\n",
    "\n",
    "h = # TODO: try different values between 1 and 4.\n",
    "\n",
    "# Grid of xs at which to evaluate the derivative\n",
    "xs = np.arange(5,35,0.05)\n",
    "derivs = []\n",
    "for x in xs:\n",
    "    derivs.append(phat_derivative(x, h, X_observed))\n",
    "\n",
    "plt.plot(xs, derivs)\n",
    "plt.title(\"Derivative of the density $\\hat{p}_h(x)$\")\n",
    "plt.ylabel(\"Derivative of the density $\\hat{p}_h(x)$\")\n",
    "plt.xlabel(\"Velocity, x\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b. Count the number of modes in $\\hat{p}_h(x)$\n",
    "\n",
    "Using the derivative calculated above, we will now count the number of modes in $\\hat{p}_h(x)$.\n",
    "\n",
    "To do this, we will evaluate the derivative $\\frac{d}{dx}\\hat{p}_h(x)$ at a grid of points $x_1,...,x_m$ evenly spaced between $5$ and $35$ (the lower and upper bounds on the velocities in the data), and count the number of times that the derivative crosses from positive to negative.  The use of a grid of $x$'s isn't a perfect measurement of the mode count, since if we don't evaluate the derivative at enough points that are close enough together, we may miss some modes. In this lab we will make sure that the grid we use is fine enough to accurately count the number of modes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Count the modes of phat using the derivative implemented above.\n",
    "def count_modes(xs, h, X):  \n",
    "    \"\"\"Counts the number of modes in phat_h(x), approximated over the given grid of xs.\n",
    "    \n",
    "    Counts a mode every time the derivative of phat_h(x) crosses from positive (or 0)\n",
    "    to negative over the given grid of xs.\n",
    "    \n",
    "    Args: \n",
    "      xs: array of floats of length m containing points at which to evaluate the derivative.\n",
    "      h: float, bandwidth parameter in phat_h.\n",
    "      X: array of floats of length n containing the observed galaxy velocities.\n",
    "      \n",
    "    Returns:\n",
    "      int, the number of modes in phat_h(x).\n",
    "    \"\"\"\n",
    "    # First calculate the derivative at all points in xs.\n",
    "    derivatives = []\n",
    "    for x in xs:\n",
    "        derivatives.append(phat_derivative(x, h, X))\n",
    "    \n",
    "    # TODO: Iterate through all of the calculated derivatives, \n",
    "    # and add a mode every time the derivative crosses from positive to negative.\n",
    "    num_modes = # TODO: calculate this by iterating through derivatives.\n",
    "    \n",
    "    return num_modes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the number of modes for different values of h.\n",
    "# No TODOs here, just run this cell to plot.\n",
    "# This figure should look similar to the figure in Discussion 10.\n",
    "# This cell may take a few seconds to run.\n",
    "xs = np.arange(5,35,0.05)\n",
    "hs = np.arange(0.3,4,0.1)\n",
    "mode_counts = []\n",
    "for h in hs:\n",
    "    mode_counts.append(count_modes(xs, h, X_observed))\n",
    "\n",
    "plt.plot(hs, mode_counts)\n",
    "plt.title(\"Number of modes in $\\hat{p}_h(x)$\")\n",
    "plt.ylabel(\"Number of modes\")\n",
    "plt.xlabel(\"Bandwidth h\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Hypothesis test\n",
    "\n",
    "Now that we've defined the density estimate $\\hat{p}_h(x)$ and figured out how to count the number of modes in $\\hat{p}_h(x)$, we will move on to testing whether or not a multimodal distribution can reasonably fit our data $X_1,...,X_n$.\n",
    "\n",
    "In the plot in part 1b), you should have observed that the number of modes in $\\hat{p}_h(x)$ decreases monotonically as $h$ increases. Let $H_1$ be the minimal bandwidth value $h$ for which $\\hat{p}_h(x)$ is unimodal. \n",
    "\n",
    "\\begin{align}\n",
    "    H_1 & = \\min \\{h \\colon m(\\hat{p}_h) = 1, \\, m(\\hat{p}_{h'}) > 1 \\text{ for all } h' < h\\}.\n",
    "\\end{align}\n",
    "\n",
    "We will use $H_1$ as the test statistic. \n",
    "\n",
    "Notice that $H_1$ depends on the data $X$, because the function $\\hat{p}_h(x)$ depends on the data $X$.\n",
    "\n",
    "##  Computing the $p$-value\n",
    "\n",
    "For our particular observed dataset $X$, let $h_1$ be the observed minimal bandwidth value $h$ for which $\\hat{p}_h(x)$ is unimodal. The $p$-value for our hypothesis test is \n",
    "\n",
    "$$P_{0}(H_1 \\geq h_1),$$\n",
    "\n",
    "where $P_0$ is the probability under the null hypothesis that the $X_i$ are drawn from a unimodal distribution. This $p$-value represents the probability under the null hypothesis that we observe a value as extreme as $h_1$.\n",
    "\n",
    "To perform a hypothesis test at significance level $\\alpha$, we reject the null hypothesis if the $p$-value is less than $\\alpha$:\n",
    "$$P_{0}(H_1 \\geq h_1) \\leq \\alpha. $$\n",
    "\n",
    "Now, we need to calculate the $p$-value. Unfortunately, we don't have a closed form for the distribution of the test statistic $H_1$ under the null hypothesis that the $X_i$ are drawn from a unimodal distribution. In fact, we don't even know what distribution the $X_i$ are drawn from, only that it's unimodal! Still, to estimate the distribution of the test statistic $H_1$, we need to pick some distribution to use for the distribution of the $X_i$'s under the null hypothesis.\n",
    "\n",
    "Among the parameterized densities $\\hat{p}_h(x)$, the density $\\hat{p}_{h_1}(x)$ the closest unimodal distribution  to the empirical distribution $p$ of the observed data. So, we will use $\\hat{p}_{h_1}(x)$ as the distribution of the $X_i$'s under the null hypothesis.\n",
    "\n",
    "Therefore, the $p$-value that we will calculate is $$P_{X_i \\sim \\hat{p}_{h_1}}(H_1 \\geq h_1).$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## a. Calculate $h_1$\n",
    "To calculate the $p$-value, the first thing we need to do is calculate $h_1$. To do this, we will try different values of $h$ until we find the smallest value such that the density estimate $\\hat{p}_h$ has $2$ modes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No TODOs here, just understand what this function is doing.\n",
    "def find_h1(xs, X, h_min=0.3, h_max=4, h_err = 0.01, k=1):\n",
    "    \"\"\"Calculates h1, the minimum bandwidth h such that the density estimate phat_h has k modes.\n",
    "    \n",
    "    Chooses h1 from within an interval bounded by h_min and h_max, within error h_err.\n",
    "    \n",
    "    Args:\n",
    "      xs: array of floats containing points xs to use to count the number of modes in phat_h.\n",
    "      X: array of floats of length n containing the observed galaxy velocities.\n",
    "      h_min: float, minimum h to try.\n",
    "      h_max: float, maximum h to try.\n",
    "      h_err: float, allowed error of h, or step size of hs to try between h_min and h_max.\n",
    "      k: number of modes being tested in the hypothesis test.\n",
    "      \n",
    "    Returns:\n",
    "      h1: minimum bandwith h among candidate hs such that phat_h has k modes.\n",
    "    \"\"\"\n",
    "    # Perform a binary search to find the minimum bandwith h1.\n",
    "    h_opt = 0\n",
    "    h_min = hs[0]\n",
    "    h_max = hs[-1]\n",
    "    modes_min = count_modes(xs, h_min, X)\n",
    "    modes_max = count_modes(xs, h_max, X)\n",
    "    while h_max - h_min > h_err:\n",
    "        h_opt = (h_min + h_max) / 2\n",
    "        modes_opt = count_modes(xs, h_opt, X)\n",
    "        if modes_opt > k:\n",
    "            h_min = h_opt\n",
    "            modes_min = modes_opt\n",
    "        else:\n",
    "            h_max = h_opt\n",
    "            modes_max = modes_opt\n",
    "    return h_max"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the value $h_1$ for the null hypothesis, we apply this function over the observed data $X_1,...,X_n$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No TODOs here, just run this cell to calculate the value of h1 using the function above.\n",
    "# If everything is correct you should expect this value to be close to 3.05.\n",
    "xs = np.arange(5,35,0.05)\n",
    "h1 = find_h1(xs, X_observed, k=1)\n",
    "print(\"Estimate value of h_1:\", h1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  b. Sampling from $\\hat{p}_{h_1}$ using the bootstrap\n",
    "\n",
    "To calculate the $p$-value, we will first draw i.i.d. samples from $\\hat{p}_{h_1}$, and then observe the number of times that the $H_1$ calculated from those samples is greater than or equal to $h_1$. We will use the bootstrap to draw the i.i.d. samples from $\\hat{p}_{h_1}$.\n",
    "\n",
    "Let $Z^{*} = (Z_1^*, \\ldots, Z_{82}^*)$ denote a bootstrap sample from the dataset. It can be shown that \n",
    "$Z_i^* + h_1 \\epsilon_i$ for $\\epsilon_i \\sim \\mathcal{N}(0, 1)$ gives i.i.d. samples from $\\hat{p}_{h_1}$.\n",
    "\n",
    "This leads to the following bootstrap algorithm: \n",
    "\n",
    "1. Draw $B$ independent bootstrap samples $X^{*(1)}, \\ldots, X^{*(B)}$ from the null distribution $\\hat{p}_{h_1}$, where in spirit,\n",
    "    \\begin{align}\n",
    "        X_i^{*(b)} & = Z_i^{*(b)} + h_1 \\epsilon_i^{(b)} \\\\\n",
    "        \\epsilon_i^{(b)} & \\sim \\mathcal{N}(0, 1)\n",
    "    \\end{align}\n",
    "    \n",
    "    Since the variance of the bootstrap sample has been increased by adding the normal error term, the data are usually rescaled to have the same sample variance as the original observations. So, it will actually work better if we replace the equation above in the algorithm with \n",
    "    \n",
    "    \\begin{align}\n",
    "        X_i^{*(b)} & = \\bar{Z}^{*(b)} + (1 + h_1^2/\\hat{\\sigma}^2)^{-1/2} (Z_i^{*(b)} - \\bar{Z}^{*(b)} + h_1\\epsilon_i^{(b)}).\n",
    "    \\end{align}\n",
    "    \n",
    "    where $\\bar{Z}^{*(b)}$ is the sample mean of the bootstrap samples $Z^{*(b)}$.\n",
    "    \n",
    "    We'll use this second, more complicated variance scaling in the code.\n",
    "    \n",
    "2. Evaluate the $B$ bootstrap replicates of the test statistic $H_1^{*(b)}$ for $b = 1, \\ldots, B$.\n",
    "3. Estimate the $p$-value using these bootstrap replicates (which provide an estimate of the distribution of the test statistic under the null hypothesis):\n",
    "    \\begin{align}\n",
    "        \\text{estimate of }  \\mathbb{P}_0(H_1 \\geq h_1) = \\frac{1}{B} \\sum_{b = 1}^B 1[H_1^{*(b)} \\geq h_1].\n",
    "    \\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: estimate the p-value using bootstrap samples from the observed data.\n",
    "def estimate_p_value(X, B, k=1):\n",
    "    \"\"\"Estimates the p-value for the hypothesis test.\n",
    "    \n",
    "    Args: \n",
    "      X: array of floats of length n containing the observed galaxy velocities.\n",
    "      B: number of bootstrap samples to draw.\n",
    "      n: number of samples to draw per bootstrap sample.\n",
    "      k: number of modes we are testing for.\n",
    "    \n",
    "    Returns:\n",
    "      float, an estimate of the p-value.\n",
    "    \"\"\"\n",
    "    # Find h1 for the distribution under the null hypothesis.\n",
    "    xs = np.arange(5,35,0.05)\n",
    "    h1 = find_h1(xs, X, k=k)\n",
    "    # Count of the number of times H1 >= h1.\n",
    "    H1_greater_count = 0\n",
    "    # Variance of the observed data X for rescaling the data.\n",
    "    X_var = np.var(X)\n",
    "    n = len(X)\n",
    "    for _ in range(B):\n",
    "        # TODO: obtain the bootstrap sample Z*. \n",
    "        # Z_star should be an array of n samples drawn from the data array X, sampled with replacement.\n",
    "        # Hint: use np.random.choice.\n",
    "        Z_star = # TODO: obtain the bootstrap sample Z*. \n",
    "        \n",
    "        Z_bar = np.mean(Z_star)\n",
    "        epsilon = np.random.normal(size=n)\n",
    "        X_star = Z_bar + (1 / sqrt(1 + ((h1**2) / X_var))) * (Z_star - Z_bar + (h1 * epsilon))\n",
    "        \n",
    "        # Check if H1 >= h1. Instead of explicitly calculating H1 (which could take long), \n",
    "        # we are using a shortcut where we count the number of modes in X_star under bandwidth value h1.\n",
    "        # If the counted number of modes is greater than the number of modes used to find h1 \n",
    "        # for the observed data, then the bandwidth value H1 is greater than or equal to the bandwidth value h1.\n",
    "        # This is true because of number of modes is monotonically decreasing in the bandwidth value h.\n",
    "        modes = count_modes(xs, h1, X_star)\n",
    "        if modes > k:\n",
    "            H1_greater_count += 1\n",
    "             \n",
    "    return H1_greater_count / B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No TODOs here, run this cell to calculate the p-value.\n",
    "p_val_1 = estimate_p_value(X_observed, 100, k=1)\n",
    "print(\"p-value for test for more than 1 mode:\", p_val_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c. Try testing for different numbers of modes.\n",
    "\n",
    "Up to this point, we've been focusing on testing whether the distribution has more than 1 mode. With our estimate of p-value above, we should have observed that the p-value for the null hypothesis that the distribution has 1 mode is very small (close to 0). \n",
    "\n",
    "If we reject the hypothesis that the distribution of the data has 1 mode, what about testing if the distribution has more than $k$ modes? Turns out we can apply the same techniques to test \n",
    "\n",
    "$$H_0: m(p) = k$$ \n",
    "$$H_A: m(p) > k$$ \n",
    "\n",
    "Below, we apply the same techniques to estimate the $p$-values for $k = 2$ and $k = 3$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No TODOs here, run this cell to calculate the p-value.\n",
    "# k = 2\n",
    "p_val_2 = estimate_p_value(X_observed, 100, k=2)\n",
    "print(\"p-value for test for more than 2 modes:\", p_val_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No TODOs here, run this cell to calculate the p-value.\n",
    "# k = 3\n",
    "p_val_3 = estimate_p_value(X_observed, 100, k=3)\n",
    "print(\"p-value for test for more than 3 modes:\", p_val_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: for which values of $k$ were you able to reject the null hypothesis? Did this match your expectation of the number of modes in the data based on looking at the initial histogram?\n",
    "\n",
    "TODO: fill in your answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
